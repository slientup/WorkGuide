## 从0开始学架构

### 一.基础架构
#### 架构选型评估维度
![架构设计评估维度](https://static001.geekbang.org/resource/image/b5/e3/b584ae29cc17bba9b7ad609e6ca2aae3.png)

这里缺少一个**开发周期的维度**

架构师经过思考后，给出了最终选择备选方案 2，原因有：
- 排除备选方案 1 的主要原因是可运维性，因为再成熟的系统，上线后都可能出问题，如果出问题无法快速解决，则无法满足业务的需求；并且 Kafka 的主要设计目标是高性能日志传输，
而我们的消息队列设计的主要目标是业务消息的可靠传输。
- 排除备选方案 3 的主要原因是复杂度，目前团队技术实力和人员规模（总共 6 人，还有其他中间件系统需要开发和维护）无法支撑自研存储系统（参考架构设计原则 2：简单原则）。
- 备选方案 2 的优点就是复杂度不高，也可以很好地融入现有运维体系，可靠性也有保障。

**选择方案1：**

案例很典型，所在项目，先选了3，1.0上线后效果不错，后期业务扩展，投入跟不上，3的缺点不断暴露，到后来大家就在吐槽为啥要造轮子。开始否决3，重构, 选择了1，运维话语权弱，被忽略了。
至于为啥不选2，就是面子上过不去，拿不出手。项目不光是为了业务，也为了架构师，领导的面子，被拿来和公司内其他项目做横向比较时，比较好吹。
至于运维的哥们，也乐意学些新东西，提升自我价值。所以，选择1大家都开心，除了项目的投入变大。

#### 细节设计
**1. 细化设计点 1：数据库表如何设计？**
- 数据库设计两类表，一类是**日志表**，用于消息写入时快速存储到 MySQL 中；另一类是消息表，**每个消息队列一张表**。
- 业务系统发布消息时，首先写入到日志表，日志表写入成功就代表消息写入成功；后台线程再从日志表中读取消息写入记录，将消息内容写入到消息表中。
- 业务系统读取消息时，从消息表中读取。
- 日志表表名为 MQ_LOG，包含的字段：日志 ID、发布者信息、发布时间、队列名称、消息内容。
- 消息表表名就是队列名称，包含的字段：消息 ID（递增生成）、消息内容、消息发布时间、消息发布者。
- 日志表需要及时清除已经写入消息表的日志数据，消息表最多保存 30 天的消息数据

采用**日志表**原因是：**尾部追加，性能高**

**2. 细化设计点 2：数据如何复制？**

直接采用 MySQL 主从复制即可，只复制消息存储表，不复制日志表。

**3. 细化设计点 3：主备服务器如何倒换？**
采用 ZooKeeper 来做主备决策，主备服务器都连接到 ZooKeeper 建立自己的节点，主服务器的路径规则为“/MQ/server/ 分区编号 /master”，备机为“/MQ/server/ 分区编号 /slave”，节点类型为 EPHEMERAL。

备机监听主机的节点消息，当发现主服务器节点断连后，备服务器修改自己的状态，对外提供消息读取服务。

**4. 细化设计点 4：业务服务器如何写入消息？**
- 消息队列系统设计两个角色：生产者和消费者，每个角色都有唯一的名称。
- 消息队列系统提供 SDK 供各业务系统调用，SDK 从配置中读取所有消息队列系统的服务器信息，SDK 采取轮询算法发起消息写入请求给主服务器。如果某个主服务器无响应或者返回错误，SDK 将发起请求发送到下一台服务器。

**5. 细化设计点 5：业务服务器如何读取消息**
- 消息队列系统提供 SDK 供各业务系统调用，SDK 从配置中读取所有消息队列系统的服务器信息，轮流向所有服务器发起消息读取请求。
- 消息队列服务器需要**记录每个消费者的消费状态**，即当前消费者已经读取到了哪条消息，当收到消息读取请求时，返回下一条未被读取的消息给消费者。

**6. 细化设计点 6：业务服务器和消息队列服务器之间的通信协议如何设计？**

**7.可以完善的细节**
1. 发送端和消费端如何寻址

   利用zookeeper做注册中心，把broker的地址注册到zk上，发送端和消费端只要配置注册中心的地址即可获取集群所以broker地址，当有broker下线时，发送端和消费端能及时更新broker地址。
2. 发送端消息重试

   当发送消息发生网络异常时（不包括超时异常），可以重新选择下一台broker来重试发送，重试策略可以自定义。
   
3. 消息消费采用pull还是push？

   考虑push模式会更复杂，故放弃，采用pull模式，消费端主动去拉，为了达到与push模式相同的低延迟效果，可以采用长轮询的方式，消费端轮询拉取消息费，当有消费可消费时，返回消息，如果没有可消费的消息，挂起当前线程，直到超时或者有可消费的消息为止。

4. 消息重复问题

   消息中间件不解决消息重复的问题，有业务系统自己根据业务的唯一id去重。
   
5. 顺序消息

   发送端在发生顺序消息时，只发送到相同broker的相同队列，消费端消费时，顺序消息只能由同一个消费端消息。
   
6. 定时消息
   
   发送端指定消息延时多长时间消费，**broker端定时扫描定时消息**，达到延时时间的消息加入到消费队列。
  
7. 事务消息

   发送端分两步，先预发送消息，broker端只记录消息为预发送状态，再执行本地事务，然后再根据本地事务的成功或者失败发送确认消息（回滚还是提交），这步如果发生异常，broker启动定时任务，把未确认的消息发送给发送端回查事务状态（需要发送端提供回查接口）
   
### 二.高性能架构模式

#### 高性能数据库集群：读写分离
读写分离的实现逻辑并不复杂，但有两个细节点将引入设计复杂度：**主从复制延迟**和**分配机制**

**主从复制延迟**

以 MySQL 为例，主从复制延迟可能达到 1 秒，如果有大量数据同步，延迟 1 分钟也是有可能的。

1. 写操作后的读操作指定发给数据库主服务器
   例如，注册账号完成后，登录时读取账号的读操作也发给数据库主服务器。这种方式和业务强绑定，对业务的侵入和影响较大，如果哪个新来的程序员不知道这样写代码，就会导致一个 bug。

2. 读从机失败后再读一次主机

   这就是通常所说的“二次读取”，二次读取和业务无绑定，只需要对底层数据库访问的 API 进行封装即可，实现代价较小，不足之处在于如果有很多二次读取，将大大增加主机的读操作压力。例如，黑客暴力破解账号，会导致大量的二次读取操作，主机可能顶不住读操作的压力从而崩溃。

3. 关键业务读写操作全部指向主机，非关键业务采用读写分离

   例如，对于一个用户管理系统来说，注册 + 登录的业务读写操作全部访问主机，用户的介绍、爱好、等级等业务，可以采用读写分离，因为即使用户改了自己的自我介绍，在查询时却看到了自我介绍还是旧的，业务影响与不能登录相比就小很多，还可以忍受。

**分配机制**
1. 程序代码封装(用户端端侧调用数据库选择jar)
2. 中间件封装(对程序来说中间件就是数据库)

**其他**

  我个人的想法是可以加入**缓存**，例如注册后登录这种业务，可以在注册后加入数据库，并加入缓存，登录的时候先查缓存再查库表。例如存入redis中并设置十分钟的过期时间。登录的时候先查redis，再查库表，如果redis中没有，说明就是过期的数据，这时候查从机就肯定存在了，希望能得到老师的点评，谢谢。
  
  **优化顺序：** SQL优化——缓存——读写分离——分库分表


#### 高性能数据库集群：分库分表

单台数据库服务器的存储能力会成为系统的瓶颈:
- 数据量太大，读写的性能会下降，即使有索引，索引也会变得很大，性能同样会下降。
- 数据文件会变得很大，数据库备份和恢复需要耗费很长时间。
- 数据文件越大，极端情况下丢失数据的风险越高（例如，机房火灾导致数据库主备机都发生故障）。
##### 业务分库
指的是按照**业务模块**将数据分散到不同的数据库服务器。例如，一个简单的电商网站，包括用户、商品、订单三个业务模块，我们可以将用户数据、商品数据、订单数据分开放到三台不同的数据库服务器上，而不是将所有数据都放在一台数据库服务器上

**带来问题：**
1. join 操作问题
  业务分库后，原本在同一个数据库中的表分散到不同数据库中，导致无法使用 SQL 的 join 查询
2. 事务问题
  原本在同一个数据库中不同的表可以在同一个事务中修改，业务分库后，表分散到不同的数据库中，无法通过事务统一修改。
  
##### 分表

单表数据拆分有两种方式：`垂直分表`和`水平分表`

`垂直分表`带来的问题：**操作的数量要增加**，原来只需要查询`一次`，现在却需要查询`两次`

`水平分表` 带来的问题：

- 路由  水平分表后，某条数据具体属于哪个切分后的子表，需要增加路由算法进行计算，这个算法会引入一定的复杂性

**范围路由：** 选取有序的数据列（例如，整形、时间戳等）作为路由的条件，不同分段分散到不同的数据库表中。以最常见的用户 ID 为例，路由算法可以按照 1000000 的范围大小进行分段，1 ~ 999999 放到数据库 1 的表中，1000000 ~ 1999999 放到数据库 2 的表中，以此类推

**Hash路由：** 选取某个列（或者某几个列组合也可以）的值进行 Hash 运算，然后根据 Hash 结果分散到不同的数据库表中

**配置路由：** 配置路由就是路由表，用一张独立的表来记录路由信息。同样以用户 ID 为例，我们新增一张 user_router 表，
这个表包含 user_id 和 table_id 两列，根据 user_id 就可以查询对应的 table_id

- count() 操作  记录数表：具体做法是新建一张表，假如表名为“记录数表”，包含 table_name、row_count 两个字段，每次插入或者删除子表数据成功后，都更新“记录数表
- order by 操作   水平分表后，数据分散到多个子表中，排序操作无法在数据库中完成，只能由业务代码或者数据库中间件分别查询每个子表中的数据，然后汇总进行排序

##### 实现方法
   和数据库读写分离类似，分库分表具体的实现方式也是“程序代码封装”和“中间件封装”，但实现会更复杂。读写分离实现时只要识别`SQL`操作是**读操作**还是**写操作**，通过简单的判断 SELECT、UPDATE、INSERT、DELETE 几个关键字就可以做到，而分库分表的实现除了**要判断操作类型**外，还要判断 SQL 中具体需要操作的表、操作函数（例如 count 函数)、order by、group by 操作等，然后再根据不同的操作进行不同的处理。例如 order by 操作，需要先从多个库查询到各个库的数据，然后再重新 order by 才能得到最终的结果.


#### 高性能NoSQL
关系数据库存在如下缺点：

-  关系数据库存储的是行记录，无法存储数据结构

   以微博的关注关系为例，“我关注的人”是一个用户 ID 列表，使用关系数据库存储只能将列表拆成多行，然后再查询出来组装，无法直接存储一个列表。
   
-  关系数据库的`schema`扩展很不方便

   关系数据库的表结构 schema 是强约束，操作不存在的列会报错，业务变化时扩充列也比较麻烦，需要执行 DDL（data definition language，如 CREATE、ALTER、DROP 等）语句修改，而且修改时可能会长时间锁表（例如，MySQL 可能将表锁住 1 个小时）

- 关系数据库在大数据场景下 I/O 较高
  
  如果对一些大量数据的表进行统计之类的运算，关系数据库的 I/O 会很高，因为即使**只针对其中某一列进行运算，关系数据库也会将整行数据从存储设备读入内存**.
 
- 关系数据库的全文搜索功能比较弱

  关系数据库的全文搜索只能使用 like 进行整表扫描匹配，性能非常低，在互联网这种搜索复杂的场景下无法满足业务要求

针对上述问题，分别诞生了不同的 NoSQL 解决方案，这些方案与关系数据库相比，在某些应用场景下表现更好。但世上没有免费的午餐，NoSQL 方案带来的优势，
本质上是牺牲`ACID`中的**某个或者某几个特性**

因此我们不能盲目地迷信`NoSQL`是银弹，而应该将 NoSQL 作为 SQL 的一个有力补充，NoSQL != No SQL，而是 **NoSQL = Not Only SQL**

**常见的 NoSQL 方案分为 4 类**
- K-V 存储：解决关系数据库无法存储数据结构的问题，以 `Redis` 为代表。
- 文档数据库：解决关系数据库强 schema 约束的问题，以 `MongoDB` 为代表。
- 列式数据库：解决关系数据库大数据场景下的 I/O 问题，以 `HBase`为代表。
- 全文搜索引擎：解决关系数据库的全文搜索性能问题，以 `Elasticsearch` 为代表

`redis`主要解决结构性数据问题，缺点主要体现在并不支持完整的 ACID 事务，Redis 虽然提供事务功能，但 Redis 的事务和关系数据库的事务不可同日而语，Redis 的事务只能保证`隔离性`和`一致性（I 和 C），无法保证原子性和持久性（A 和 D）`
`mongodb`主要解决schema的问题，有以下特点：1. 新增字段简单，无需做任何操作，2. 历史数据不会出错  3. 可以很容易存储复杂数据(json数据类型)

缺点是：最主要的代价就是不支持事务，无法实现关系数据库的`join`操作。

`列式数据库` 行式存储即使最终只使用一列，也会将所有行数据都读取出来,而列式存储就只会读取**一列**数据 但当需要频繁地更新多个列。因为列式存储将不同列存储在磁盘上不连续的空间，导致更新多个列时磁盘是随机写操作；而行式存储时同一行多个列都存储在连续的空间，一次磁盘写操作就可以完成，列式存储的随机**写效率**要远远低于行式存储的写效率,所以适用的场景是大数据离线分析

`全文搜索引擎` 

传统数据库面临的缺点；
- 全文搜索的条件可以随意排列组合，如果通过索引来满足，则索引的数量会非常多。 
- 全文搜索的模糊匹配方式，索引无法满足，只能用 like 查询，而`like`查询是整表扫描，效率非常低。

全文搜索基本原理：

全文搜索引擎的技术原理被称为“倒排索引”(Inverted index),其基本原理是建立**单词**到**文档**的索引

**倒排索引示例**
![](https://static001.geekbang.org/resource/image/3c/bd/3cfa4abdcc22015ade669d9a844ae1bd.jpg)

关于NoSQL，看过一张图，挺形象：“1970，We have no SQL”-“1980，Know SQL”-“2000，NoSQL”-“2005，Not only SQL”-“2015，No，SQL”。
目前，一些新型数据库，同时具备了NoSQL的扩展性和关系型数据库的很多特性。

关系型和NoSQL数据库的选型。考虑几个指标，数据量、并发量、实时性、一致性要求、读写分布和类型、安全性、运维性等。根据这些指标，软件系统可分成几类。
1. 管理型系统，如运营类系统，首选关系型。
2. 大流量系统，如电商单品页的某个服务，后台选关系型，前台选内存型。
3. 日志型系统，原始数据选列式，日志搜索选倒排索引。
4. 搜索型系统，指站内搜索，非通用搜索，如商品搜索，后台选关系型，前台选倒排索引。
5. 事务型系统，如库存、交易、记账，选关系型+缓存+一致性协议，或新型关系数据库。
6. 离线计算，如大量数据分析，首选列式，关系型也可以。
7. 实时计算，如实时监控，可以选时序数据库，或列式数据库。





 
