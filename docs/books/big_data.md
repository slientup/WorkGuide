# 极客时间 从0开始学大数据

### 大数据生态

![大数据生态](https://static001.geekbang.org/resource/image/ca/73/ca6efc15ead7fb974caaa2478700f873.png)

### 大数据应用的发展 

从数据搜索——数据仓库时代——数据挖掘时代——机器学习时代  无论是哪一个时代都是**发现数据中的规律并为我们提供价值**，在最开始的搜索引擎时代，是对每条网页的分词做统计，
数据仓库时代需要从海量的数据中获取需要的数据(如做报表统计等)，而数据挖掘时代实际上想做数据与数据之间的关联性分析，而机器学习时代，是对某个场景的结果做统计分析，，选择其中的最优解。无论是处在哪个时代，赋予数据灵魂的始终是人的智慧，是人决定了如何利用这海量的数据，是人的智慧决定了大数据应用的上限。

## hadoop大数据原理和架构

### 移动计算比移动数据更划算

传统软件计算处理模型，都是`输入---计算---输出`模型

但在大数据领域，常常需要处理的数据时以PB为单位的，如果一个程序需要输入PB的数据量，然后进行处理，这个程序会崩溃的，而大数据解决的思想就是分布式，分而治之

大数据计算处理通常针对的是网站的存量数据，将其中规律统计出来后进行改善以提升服务质量

我们在分布式的场景下，应该是移动数据还是移动计算程序啦？答案是移动计算，因为计算程序往往很小，而数据却会很大，移动数据的成本会大得多。

### 从RAID看垂直伸缩到水平伸缩的演化

如果一个文件的大小超过了一张磁盘的大小，你该如何存储？

单机时代，主要的解决方案是`RAID`；分布式时代，主要解决方案是分布式文件系统

存储系统要解决如下问题？
- 存储容量，如何存储大规模的文件？
- 读写速度，单个磁盘的读写速度一般在几十兆，在数据是以PB为单位的大数据领域，如何快速读取？
- 数据的备份 其中一块磁盘异常了 数据不会丢失

`raid` 是将多个磁盘组成一个阵列，统一对外提供服务，改善了存储容量、读写速度，增强磁盘的可用性和容错能力。

几种常用raid
![](https://static001.geekbang.org/resource/image/54/af/54e170b7438fe3b8f8196dbfbc943baf.jpg)
raid效率比较
![](https://static001.geekbang.org/resource/image/e2/2f/e2fb7ec97e6127c1b03e83daeff0232f.jpg)

`raid`是一种垂直扩展的思路，即在单机条件下做相应的冗余可靠性，但是单机无论有多强都是有极限的，而且成本会越来越高，相反，如果采用分布式，将垂直的方式
改成`水平伸缩`的模式就能实现无限的扩张，实现更强的计算能力。

RAID 技术只是在单台服务器的多块磁盘上组成阵列，大数据需要更大规模的存储空间和更快的访问速度。将 RAID 思想原理应用到分布式服务器集群上，就形成了 Hadoop 分布式文件系统 HDFS 的架构思想

连续写入：写入只寻址一次 存储位置与逻辑位置相邻 不用多次寻址

随机写入：每写一次 便寻址一次 增加了磁盘的寻址时间

总结：垂直伸缩总有尽头，水平伸缩理论上是没有止境的

### 新技术层出不穷，HDFS依然是存储的王者

从大数据发展至今，计算框架，应用场景等都在不断的变化，唯一不变的就是存储系统`HDFS`,因为大数据的核心在**数据**

为什么 HDFS 的地位如此稳固呢？

在整个大数据体系里面，最宝贵、最难以代替的资产就是数据，**大数据所有的一切都要围绕数据展开**。HDFS 作为最早的大数据存储系统，存储着宝贵的数据资产，各种新的算法、框架要想得到人们的广泛使用，必须支持 HDFS 才能获取已经存储在里面的数据。所以大数据技术越发展，新技术越多，HDFS 得到的支持越多，我们越离不开 HDFS。**HDFS 也许不是最好的大数据存储技术，但依然最重要的大数据存储技术**

Hadoop 分布式文件系统 HDFS 的设计目标是管理数以千计的服务器、数以万计的磁盘，将这么大规模的服务器计算资源当作一个单一的存储系统进行管理，对应用程序提供数以 PB 计的存储容量，让应用程序像使用普通文件系统一样存储大规模的文件数据。

我们在设计一个产品的时候，要解决用户的问题，也要对用户无感知，不改变它的使用习惯。

**HDFS架构图**
![](https://static001.geekbang.org/resource/image/65/d7/65efd126cbcf3930a706f64c6e6457d7.jpg)

**DataNode** 负责文件数据的存储和读写操作，HDFS 将文件数据分割成若干数据块（`Block`），每个 DataNode 存储一部分数据块，这样文件就分布存储在整个 HDFS 服务器集群中  **数据块**是基本单位

**NameNode** 负责整个分布式文件系统的元数据（`MetaData`）管理，也就是文件路径名、数据块的 ID 以及存储位置等信息，相当于操作系统中文件分配表（FAT）的角色 HDFS 为了保证数据的高可用，会将一个数据块复制为多份（缺省情况为 3 份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上

**数据块多份复制存储的示意图**
![](https://static001.geekbang.org/resource/image/6f/ac/6f2faa48524251ad77e55e3565095bac.jpg)
图中对于文件 /users/sameerp/data/part-0，其复制备份数设置为 2，存储的 BlockID 分别为 1、3。Block1 的两个备份存储在 DataNode0 和 DataNode2 两个服务器上，Block3 的两个备份存储 DataNode4 和 DataNode6 两个服务器上，上述任何一台服务器宕机后，每个数据块都至少还有一个备份存在，不会影响对文件 /users/sameerp/data/part-0 的访问

**HDFS的不同层面的高可用设计**
1. 数据存储故障容错  通过`校验和`的方式

磁盘介质在存储过程中受环境或者老化影响，其存储的数据可能会出现错乱。HDFS 的应对措施是，对于存储在 DataNode 上的数据块，计算并存储校验和（CheckSum）。在读取数据的时候，重新计算读取出来的数据的校验和，如果校验不正确就抛出异常，应用程序捕获异常后就到其他 DataNode 上读取备份数据。

2. 磁盘故障容错  datanode监控磁盘状态并上报给namenode

如果 DataNode 监测到本机的某块磁盘损坏，就将该块磁盘上存储的所有 BlockID 报告给 NameNode，NameNode 检查这些数据块还在哪些 DataNode 上有备份，通知相应的 DataNode 服务器将对应的数据块复制到其他服务器上，以保证数据块的备份数满足要求

3. datanode故障容错 datanode和namenode的心跳机制

DataNode 会通过心跳和 NameNode 保持通信，如果 DataNode 超时未发送心跳，NameNode 就会认为这个 DataNode 已经宕机失效，立即查找这个 DataNode 上存储的数据块有哪些，以及这些数据块还存储在哪些服务器上，随后通知这些服务器再复制一份数据块到其他服务器上，保证 HDFS 存储的数据块备份数符合用户设置的数目，即使再出现服务器宕机，也不会丢失数据

4. NameNode 故障容错 

namenode是整个机器的核心，一定不能故障 主备机制 用zookeeper做znode锁
![](https://static001.geekbang.org/resource/image/7c/89/7cb2668644c32364beab0b69e60b3689.png)

可用性是在网站架构设计中必须考虑的一个因素，因为我们随时都在面对着意外的发生，内存、CPU、主板、磁盘会损坏，服务器会宕机，网络会中断，机房会停电等

**保证系统的可用性一般有三种方法：冗余备份，失效转移，降级限流**

比如冗余备份，任何程序、任何数据，都至少要有一个备份，也就是说程序至少要部署到两台服务器，数据至少要备份到另一台服务器上。此外，稍有规模的互联网企业都会建设多个数据中心，数据中心之间互相进行备份，用户请求可能会被分发到任何一个数据中心，即所谓的异地多活，在遭遇地域性的重大故障和自然灾害的时候，依然保证应用的高可用

当要访问的程序或者数据无法访问时，需要将访问请求转移到备份的程序或者数据所在的服务器上，这也就是**失效转移**。失效转移你应该注意的是失效的鉴定

当大量的用户请求或者数据处理请求到达的时候，由于计算资源有限，可能无法处理如此大量的请求，进而导致资源耗尽，系统崩溃。这种情况下，可以拒绝部分请求，即进行限流；也可以关闭部分功能，降低资源消耗，即进行降级






















